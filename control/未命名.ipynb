{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a8c94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish running!\n",
      "optimal actions started from 0: [1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "optimal state seqence started from 0: [0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "def argmax(domain, fn):\n",
    "    max_x = None \n",
    "    max_y = None\n",
    "    for x in domain:\n",
    "        y = fn(x)\n",
    "        if (max_x is None) or (y > max_y):\n",
    "            max_x = x \n",
    "            max_y = y\n",
    "    return max_x\n",
    "\n",
    "class DynamicProgramming:\n",
    "    def __init__(self, state_space, action_space, trans_fn, reward_fn, final_reward_fn=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            @T: time length [int] \n",
    "            @state_space: [list<state>] \n",
    "            @action_space: [list<action>]\n",
    "            @trans_fn: (t, x, action) -> state   [(int, state, action) -> state]\n",
    "            @reward_fn: (t, x, action) -> reward [(int, state, action) -> float]\n",
    "            @final_reward_fn: final_x -> reward  [state -> float] \n",
    "        \"\"\"\n",
    "        \n",
    "        self.state_space = state_space \n",
    "        self.action_space = action_space\n",
    "        \n",
    "        self.trans_fn = trans_fn\n",
    "        self.reward_fn =reward_fn \n",
    "        self.final_reward_fn = final_reward_fn\n",
    "        \n",
    "        self.J = None \n",
    "        self.action_path = None \n",
    "        self.state_path = None\n",
    "        \n",
    "        self.is_run = False\n",
    "        \n",
    "        \n",
    "    def run(self, T):\n",
    "        \n",
    "        \"\"\" set param \"\"\"\n",
    "        state_space = self.state_space\n",
    "        action_space = self.action_space\n",
    "        \n",
    "        trans_fn = self.trans_fn\n",
    "        reward_fn = self.reward_fn\n",
    "        final_reward_fn = self.final_reward_fn\n",
    "\n",
    "        if final_reward_fn is None:\n",
    "            final_reward_fn = lambda x: reward_fn(T, x, None)\n",
    "\n",
    "        # reward function is time independent: \n",
    "        if reward_fn.__code__.co_argcount == 2:\n",
    "            reward_fn = lambda t, x, action: reward_fn(x, action)\n",
    "\n",
    "        # transition function is time independent:\n",
    "        if trans_fn.__code__.co_argcount == 2: \n",
    "            trans_fn = lambda t, x, action: trans(x, action)\n",
    "\n",
    "        \"\"\" dynamic programming \"\"\"\n",
    "        J = dict([(x, final_reward_fn(x)) for x in state_space])   # t = T \n",
    "\n",
    "        state_path =  dict([(x, [x]) for x in state_space])\n",
    "        action_path = dict([(x, []) for x in state_space])\n",
    "\n",
    "        for t in range(T-1, -1, -1):   # t = T-1, ..., 1, 0\n",
    "            pre_J = dict()\n",
    "            pre_state_path = dict()\n",
    "            pre_action_path = dict()\n",
    "            for x in state_space:\n",
    "                fn = lambda action: reward_fn(t, x, action) + J[trans_fn(t, x, action)]\n",
    "                action = argmax(action_space, fn)  # best action at x\n",
    "                pre_J[x] = fn(action)               \n",
    "\n",
    "                pre_state_path[x] = [x] + state_path[trans_fn(t, x, action)]\n",
    "                pre_action_path[x] = [action] + action_path[trans_fn(t, x, action)]\n",
    "\n",
    "            J = pre_J\n",
    "            state_path = pre_state_path \n",
    "            action_path = pre_action_path\n",
    "\n",
    "        \n",
    "        self.J = J \n",
    "        self.state_path = state_path \n",
    "        self.action_path = action_path\n",
    "        \n",
    "        self.is_run = True \n",
    "        \n",
    "        print(\"Finish running!\")\n",
    "        \n",
    "\n",
    "    def get_optimal_actions(self, state):\n",
    "        if not self.is_run:\n",
    "            raise Exception(\"Dynamic Programming not run, try: dp.run(T=10)\") \n",
    "        \n",
    "        return self.action_path[state]\n",
    "    \n",
    "    def get_optimal_states(self, state):\n",
    "        if not self.is_run:\n",
    "            raise Exception(\"Dynamic Programming not run, try: dp.run(T=10)\") \n",
    "        return self.state_path[state]\n",
    "        \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    state_space = [0, 1]\n",
    "    action_space = [0, 1]\n",
    "    trans_fn = lambda t, x, action: action ^ x\n",
    "    reward_fn = lambda t, x, action: action + x \n",
    "    final_reward_fn = lambda x: x\n",
    "\n",
    "    dp = DynamicProgramming(state_space=state_space, \n",
    "                            action_space=action_space, \n",
    "                            trans_fn=trans_fn, \n",
    "                            reward_fn=reward_fn, \n",
    "                            final_reward_fn=final_reward_fn)\n",
    "    \n",
    "    dp.run(10)\n",
    "    print(\"optimal actions started from 0:\", dp.get_optimal_actions(0))\n",
    "    print(\"optimal state seqence started from 0:\", dp.get_optimal_states(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a2c84fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 15, 1: 16}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: [0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1], 1: [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: [1, 0, 1, 1, 1, 1, 1, 1, 1, 1], 1: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dp(T, state_space, action_space, trans_fn, reward_fn, final_reward_fn=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        @T: time length [int] \n",
    "        @state_space: [list<state>] \n",
    "        @action_space: [list<action>]\n",
    "        @trans_fn: (t, x, action) -> state   [(int, state, action) -> state]\n",
    "        @reward_fn: (t, x, action) -> reward [(int, state, action) -> float]\n",
    "        @final_reward_fn: final_x -> reward  [state -> float] \n",
    "    Return:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if final_reward_fn is None:\n",
    "        final_reward_fn = lambda x: reward_fn(T, x, None)\n",
    "    \n",
    "    # reward function is time independent: \n",
    "    if reward_fn.__code__.co_argcount == 2:\n",
    "        reward_fn = lambda t, x, action: reward_fn(x, action)\n",
    "        \n",
    "    # transition function is time independent:\n",
    "    if trans_fn.__code__.co_argcount == 2: \n",
    "        trans_fn = lambda t, x, action: trans(x, action)\n",
    "    \n",
    "    J = dict([(x, final_reward_fn(x)) for x in state_space])   # t = T \n",
    "    \n",
    "    state_path =  dict([(x, [x]) for x in state_space])\n",
    "    action_path = dict([(x, []) for x in state_space])\n",
    "    \n",
    "    for t in range(T-1, -1, -1):   # t = T-1, ..., 1, 0\n",
    "        pre_J = dict()\n",
    "        pre_state_path = dict()\n",
    "        pre_action_path = dict()\n",
    "        for x in state_space:\n",
    "            fn = lambda action: reward_fn(t, x, action) + J[trans_fn(t, x, action)]\n",
    "            action = argmax(action_space, fn)  # best action at x\n",
    "            pre_J[x] = fn(action)               \n",
    "            \n",
    "            pre_state_path[x] = [x] + state_path[trans_fn(t, x, action)]\n",
    "            pre_action_path[x] = [action] + action_path[trans_fn(t, x, action)]\n",
    "        \n",
    "        J = pre_J\n",
    "        state_path = pre_state_path \n",
    "        action_path = pre_action_path\n",
    "        \n",
    "        \n",
    "    return J, state_path, action_path\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    state_space = [0, 1]\n",
    "    action_space = [0, 1]\n",
    "    trans_fn = lambda t, x, action: action ^ x\n",
    "    reward_fn = lambda t, x, action: action + x \n",
    "    final_reward_fn = lambda x: x\n",
    "\n",
    "    J, state_path, action_path = dp(T=10, \n",
    "                                    state_space=state_space, \n",
    "                                    action_space=action_space, \n",
    "                                    trans_fn=trans_fn, \n",
    "                                    reward_fn=reward_fn, \n",
    "                                    final_reward_fn=final_reward_fn)\n",
    "    display(J)\n",
    "    display(state_path)\n",
    "    display(action_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4bd02f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.__code__.co_argcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3a8960c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 4}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = lambda x: x * x\n",
    "dict([(k, fn(k)) for k in range(3)]).copy()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3801d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def argmin_(domain, fn):\n",
    "    min_x = None \n",
    "    min_y = None\n",
    "    for x in domain:\n",
    "        y = fn(x)\n",
    "        if (min_x is None) or (y < min_y):\n",
    "            min_x = x \n",
    "            min_y = y\n",
    "    return min_x\n",
    "\n",
    "def argmin(obj, fn=None):\n",
    "    if type(obj) in [list, np.ndarray]:\n",
    "        domain = list(range(len(obj)))\n",
    "        return argmin_(domain, lambda i: obj[i])\n",
    "    if type(obj) in [dict]:\n",
    "        domain = obj.keys()\n",
    "        fn = lambda k: obj[k]\n",
    "        return argmin_(domain, fn)\n",
    "    return argmin_(obj, fn)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c543b820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "more_than = lambda x, y: x > y\n",
    "less_than = lambda x, y: x < y\n",
    "\n",
    "def argopt_(domain, fn, better_than):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        @domain: an iterable object\n",
    "        @fn: func(domain -> range)\n",
    "        @better_than: better_than(y1, y2) = True if (y1 is optimal than y2) for (y1, y2 in range)\n",
    "    Return:\n",
    "        the first optimal element in domain\n",
    "    \"\"\"\n",
    "    opt_x = None \n",
    "    opt_y = None \n",
    "    for x in domain:\n",
    "        y = fn(x)\n",
    "        if (opt_x is None) or better_than(y, opt_y):\n",
    "            opt_x = x\n",
    "            opt_y = y\n",
    "    return opt_x\n",
    "\n",
    "def argopt(obj, fn, better_than):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        @obj: an object that auto domain inference is performed on\n",
    "        @fn: a fucntion from domain to range\n",
    "        @better_than: better_than(y1, y2) = True if y1 is optimal than y2 (for y1, y2 in range)\n",
    "    Return:\n",
    "        the first optimal element in domain\n",
    "    \"\"\"\n",
    "    if type(obj) in [list, np.ndarray]:\n",
    "        domain = list(range(len(obj)))\n",
    "        if fn is None:\n",
    "            fn = lambda i: obj[i]\n",
    "    elif type(obj) in [dict]:\n",
    "        domain = obj.keys()\n",
    "        if fn is None:\n",
    "            fn = lambda k: obj[k]\n",
    "    else:\n",
    "        domain = obj\n",
    "        fn = fn\n",
    "    return argopt_(domain, fn, better_than)\n",
    "\n",
    "def argmin(obj, fn=None):\n",
    "    return argopt(obj=obj, fn=fn, better_than=less_than)\n",
    "\n",
    "def argmax(obj, fn=None):\n",
    "    return argopt(obj=obj, fn=fn, better_than=more_than)\n",
    "\n",
    "print(argmax(dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1b774947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,2,3,4,5]\n",
    "fn = lambda x: (x - 2.6) ** 2 \n",
    "argmin(x, fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
